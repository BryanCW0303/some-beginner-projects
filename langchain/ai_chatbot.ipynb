{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1c551c-7a86-410d-9b7a-cbb53717040d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import gradio as gr\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9887c5-9456-4351-ae27-6ec40e84b16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(\"deepseek_api.env\", override=True)\n",
    "\n",
    "DeepSeek_API_KEY = os.getenv(\"DEEPSEEK_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc651a2-71d0-44a5-b9ff-dcf313a2a60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a AI chatbot with conversation history\n",
    "\n",
    "model = init_chat_model(model=\"deepseek-chat\", model_provider=\"deepseek\")\n",
    "parser = StrOutputParser()\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are hoshiro, is a helpful assistant.\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "qa_chain = prompt | model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445ad75c-d91d-48ce-9954-1615d0a925aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def chat_response(message, history):\n",
    "    partial_message = \"\"\n",
    "\n",
    "    async for chunk in qa_chain.astream({\"input\": message}):\n",
    "        partial_message += chunk\n",
    "        yield partial_message\n",
    "\n",
    "\n",
    "def create_chatbot():\n",
    "\n",
    "    css = \"\"\"\n",
    "    .main-container { max-width: 1200px; margin: 0 auto; padding: 20px; }\n",
    "    .header-text { text-align: center; margin-bottom: 20px; }\n",
    "    \"\"\"\n",
    "\n",
    "    with gr.Blocks(title=\"DeepSeek Chat\", css=css) as demo:\n",
    "        with gr.Column(elem_classes=[\"main-container\"]):\n",
    "            gr.Markdown(\"# LangChain\", elem_classes=[\"header-text\"])\n",
    "            gr.Markdown(\"**AI Chatbot based on LangChain\", elem_classes=[\"header-text\"])\n",
    "\n",
    "            # chatbox\n",
    "            chatbot = gr.Chatbot(\n",
    "                height=500,\n",
    "                show_copy_button=True,\n",
    "                avatar_images=(\n",
    "                    # user avatar, bot avatar\n",
    "                    \"https://cdn.jsdelivr.net/gh/twitter/twemoji@14.0.2/assets/72x72/1f9d1-200d-1f4bb.png\",\n",
    "                    \"https://cdn.jsdelivr.net/gh/twitter/twemoji@14.0.2/assets/72x72/1f916.png\",\n",
    "                ),\n",
    "            )\n",
    "\n",
    "            with gr.Row():\n",
    "                msg = gr.Textbox(\n",
    "                    placeholder=\"Please input your question\",\n",
    "                    container=False,\n",
    "                    scale=7,\n",
    "                )\n",
    "                submit = gr.Button(\"send\", scale=1, variant=\"primary\")\n",
    "                clear = gr.Button(\"clear\", scale=1)\n",
    "\n",
    "            # handling messages and update stream\n",
    "            async def respond(message, chat_history):\n",
    "                if not message or not message.strip():\n",
    "                    # clean input\n",
    "                    yield \"\", chat_history\n",
    "                    return\n",
    "\n",
    "                # 1) add the user's message to the history and display it\n",
    "                chat_history = (chat_history or []) + [(message, None)]\n",
    "                yield \"\", chat_history\n",
    "\n",
    "                # 2) stream the ai reply\n",
    "                async for partial in chat_response(message, chat_history):\n",
    "                    chat_history[-1] = (message, partial)\n",
    "                    yield \"\", chat_history\n",
    "\n",
    "            # clean conversation history\n",
    "            def clear_history():\n",
    "                return [], \"\"\n",
    "\n",
    "            # bind events: submit on enter, click to send, click to clear\n",
    "            msg.submit(respond, [msg, chatbot], [msg, chatbot])\n",
    "            submit.click(respond, [msg, chatbot], [msg, chatbot])\n",
    "            clear.click(clear_history, outputs=[chatbot, msg])\n",
    "\n",
    "    return demo\n",
    "\n",
    "demo = create_chatbot()\n",
    "demo.launch(\n",
    "    server_name=\"0.0.0.0\",\n",
    "    server_port=7859,\n",
    "    share=False,\n",
    "    debug=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "langchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
