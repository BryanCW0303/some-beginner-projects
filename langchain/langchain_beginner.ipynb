{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4df00bd5-5897-47ba-bd12-a754f442350c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gradio as gr\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.output_parsers.boolean import BooleanOutputParser\n",
    "from langchain.output_parsers import ResponseSchema, StructuredOutputParser\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b28daefa-02d0-4261-91c8-48ae58592b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(\"deepseek_api.env\", override=True)\n",
    "\n",
    "DeepSeek_API_KEY = os.getenv(\"DEEPSEEK_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f678e1e-0602-4e03-b52a-6069d14777bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm your helpful assistant, here to provide you with accurate information, answer your questions, assist with tasks, and offer support on a wide range of topics. Whether you need help with research, writing, problem-solving, or just a friendly chat, I'm here for you. Feel free to ask me anything!\n"
     ]
    }
   ],
   "source": [
    "# initialize deepseek api client\n",
    "client = OpenAI(api_key=DeepSeek_API_KEY, base_url=\"https://api.deepseek.com\")\n",
    "\n",
    "# call deepseek api to generate answer\n",
    "response = client.chat.completions.create(\n",
    "    model=\"deepseek-chat\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant, please answer questions based on what the user asked.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Hi there, please introduce yourself.\"}\n",
    "    ],\n",
    ")\n",
    "\n",
    "# print the response result\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4f9a92e-8002-4929-b142-b57da1a4fd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = init_chat_model(model=\"deepseek-chat\", model_provider=\"deepseek\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "977f290e-7b77-4de5-bb39-c7ce83b103a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi! I'm DeepSeek-V3, your AI assistant created by DeepSeek. I'm here to help answer questions, provide insights, and assist with a wide range of topicsâ€”from general knowledge and coding to writing and productivity tips. I can analyze uploaded files, search the web when needed, and offer detailed, friendly conversations. Let me know how I can assist you today! ðŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "question = \"Hi there, please introduce yourself.\"\n",
    "\n",
    "result = model.invoke(question)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f455a158-aadb-42d9-bcd7-e80f088c3139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi! I'm DeepSeek-V3, your AI assistant created by DeepSeek. I'm here to help answer questions, provide insights, and assist with a wide range of topicsâ€”from general knowledge and coding to writing and productivity tips. I can analyze uploaded files, search the web when needed, and offer detailed, friendly conversations. Let me know how I can assist you today! ðŸ˜Š\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 81, 'prompt_tokens': 11, 'total_tokens': 92, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 11}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_08f168e49b_prod0820_fp8_kvcache', 'id': '88fe5738-0b40-491b-bdcd-ad651c8d0f9e', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--cbb5a2d9-7e69-43ca-b81a-be010e854375-0', usage_metadata={'input_tokens': 11, 'output_tokens': 81, 'total_tokens': 92, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fcfdfed-dd67-4df5-bf19-3dd6be7a17d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a chain: model + parser\n",
    "basic_qa_chain = model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a2a764b-2e20-43bc-8209-005f2b4e16aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi! I'm **DeepSeek-V3**, created by **DeepSeek**. I'm an AI assistant designed to help answer your questions, provide information, and assist with various tasks like writing, coding, learning, and more. I can process long documents (up to 128K context), support file uploads (PDFs, Word, Excel, etc.), and even perform web searches when needed.  \n",
      "\n",
      "I'm here to make your life easierâ€”so feel free to ask me anything! How can I assist you today? ðŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "result = basic_qa_chain.invoke(question)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e9e613d-b7a4-4078-9f3a-2b25a903e3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\n"
     ]
    }
   ],
   "source": [
    "prompt_template = ChatPromptTemplate([\n",
    "    (\"system\", \"you are a helpful assistant, please answer question based on what user asked\"),\n",
    "    (\"user\", \"This is user's question: {topic}, please answer yes or no\")\n",
    "])\n",
    "\n",
    "# build a chain: prompt + model + parser\n",
    "bool_qa_chain = prompt_template | model | StrOutputParser()\n",
    "question = \"1 + 1 > 2?\"\n",
    "result = bool_qa_chain.invoke({\"topic\": question})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78a3ac4b-be8a-40e0-b846-97ea93a409a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "bool_qa_chain = prompt_template | model | BooleanOutputParser()\n",
    "question = \"1 + 1 > 2?\"\n",
    "result = bool_qa_chain.invoke({\"topic\": question})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6dbcf73-9792-4721-8cfd-709cc9f1e056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "question = \"1 + 1 > 1?\"\n",
    "result = bool_qa_chain.invoke({\"topic\": question})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "add58932-a312-4668-8e1c-430e88f766a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "schemas = [\n",
    "    ResponseSchema(name=\"name\", description=\"the name of user\"),\n",
    "    ResponseSchema(name=\"age\", description=\"the age of user\")\n",
    "]\n",
    "parser = StructuredOutputParser.from_response_schemas(schemas)\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"please based on the content provided to extract user's information, and return in json format:\"\n",
    "    + \"\\n{input}\\n\\n{format_instructions}\"\n",
    ")\n",
    "\n",
    "chain = (\n",
    "    prompt.partial(format_instructions=parser.get_format_instructions())\n",
    "    | model\n",
    "    | parser\n",
    ")\n",
    "\n",
    "result = chain.invoke({\"input\": \"My name is Bryan Ng, 24 years old. I am a AI engineer\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31e718a2-94a3-44b7-bd3a-aabbff6529d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Bryan Ng', 'age': '24'}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7f8c48f2-eace-461a-a9ea-f1c86d4c1d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'time': 'September 19th', 'location': 'Seattle', 'event': 'Apple AirPods Pro 3 launch event'}\n"
     ]
    }
   ],
   "source": [
    "news_gen_prompt = PromptTemplate.from_template(\n",
    "    \"please based on the newspaper title provided, please write a short paragraph\"\n",
    "    + \"about the news content(about 100 words): \\n\\n title:{title}\"\n",
    ")\n",
    "\n",
    "news_chain = news_gen_prompt | model | StrOutputParser()\n",
    "\n",
    "schemas = [\n",
    "    ResponseSchema(name=\"time\", description=\"when the event happen\"),\n",
    "    ResponseSchema(name=\"location\", description=\"where the event happen\"),\n",
    "    ResponseSchema(name=\"event\", description=\"what is the event, please be concise\")\n",
    "]\n",
    "parser = StructuredOutputParser.from_response_schemas(schemas)\n",
    "\n",
    "summary_prompt = PromptTemplate.from_template(\n",
    "    \"please extract key information from the news content, and return it in json format\"\n",
    "    + \"\\n\\n{news}\\n\\n{format_instructions}\"\n",
    ")\n",
    "\n",
    "summary_chain = (\n",
    "    summary_prompt.partial(format_instructions=parser.get_format_instructions())\n",
    "    | model\n",
    "    | parser\n",
    ")\n",
    "\n",
    "full_chain = news_chain | summary_chain\n",
    "\n",
    "result = full_chain.invoke({\"title\": \"Apple AirPods Pro 3 will be released on 19th, September in Seattle\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c8e3530c-c9da-4100-b083-60181ec3cd83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: Based on the announcement, Apple will unveil its highly anticipated AirPods Pro 3 on September 19th at a special event in Seattle. The next generation of the popular wireless earbuds is expected to feature significant upgrades, including enhanced active noise cancellation for an even more immersive listening experience and improved transparency mode. Industry analysts also predict the integration of new health monitoring sensors, potentially tracking wellness metrics like body temperature. The launch event in Seattle marks a notable departure from Apple's typical California-based announcements, generating additional excitement for the new product's debut.\n",
      "{'time': 'September 19th', 'location': 'Seattle', 'event': 'Apple AirPods Pro 3 launch event'}\n"
     ]
    }
   ],
   "source": [
    "def debug_print(x):\n",
    "    print(\"result:\", x)\n",
    "    return x\n",
    "\n",
    "debug_node = RunnableLambda(debug_print)\n",
    "\n",
    "full_chain = news_chain | debug_node | summary_chain\n",
    "result = full_chain.invoke({\"title\": \"Apple AirPods Pro 3 will be released on 19th, September in Seattle\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9dad3389-cee9-4c10-b944-eb6d06fc6ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=\"You are hoshiro, is a helpful assistant.\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a4e0d600-4649-4b29-95ad-225eeefde0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_qa_chain = chatbot_prompt | model | StrOutputParser()\n",
    "messages_list = [\n",
    "    HumanMessage(content=\"Hi there, I am Bryan, nice to meet you.\"),\n",
    "    AIMessage(content=\"Hi, I am hoshiro, is a helpful assistant, nice to meet you too!\"),\n",
    "]\n",
    "question = \"Hello, what is my name?\"\n",
    "messages_list.append(HumanMessage(content=question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "18f54e31-461f-4eb8-94c3-d009195eac95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your name is Bryan! It's nice to meet you again. ðŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "result = basic_qa_chain.invoke({\"messages\": messages_list})\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "langchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
